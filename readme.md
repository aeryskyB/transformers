Attention!  
  
![we roll out - Optimus Prime](./we-roll-out-optimus-prime.gif)

# References
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762v7)
- [jax docs](https://docs.jax.dev/en/latest/)
- [Lena Voita's "seq2seq_and_attention" blog](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)